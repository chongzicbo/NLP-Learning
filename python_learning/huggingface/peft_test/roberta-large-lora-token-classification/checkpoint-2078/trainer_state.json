{
  "best_metric": 0.16227084398269653,
  "best_model_checkpoint": "roberta-large-lora-token-classification/checkpoint-2078",
  "epoch": 2.0,
  "global_step": 2078,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.48,
      "learning_rate": 0.0009518768046198268,
      "loss": 0.177,
      "step": 500
    },
    {
      "epoch": 0.96,
      "learning_rate": 0.0009037536092396536,
      "loss": 0.1714,
      "step": 1000
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9433928852510625,
      "eval_f1": 0.7720994475138122,
      "eval_loss": 0.18281608819961548,
      "eval_precision": 0.7415022384347538,
      "eval_recall": 0.8053304520079236,
      "eval_runtime": 9.6367,
      "eval_samples_per_second": 199.966,
      "eval_steps_per_second": 12.556,
      "step": 1039
    },
    {
      "epoch": 1.44,
      "learning_rate": 0.0008556304138594802,
      "loss": 0.1771,
      "step": 1500
    },
    {
      "epoch": 1.92,
      "learning_rate": 0.0008075072184793071,
      "loss": 0.1845,
      "step": 2000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9464819770187313,
      "eval_f1": 0.7868909919383105,
      "eval_loss": 0.16227084398269653,
      "eval_precision": 0.766342379245605,
      "eval_recall": 0.8085719430938232,
      "eval_runtime": 10.5751,
      "eval_samples_per_second": 182.22,
      "eval_steps_per_second": 11.442,
      "step": 2078
    }
  ],
  "max_steps": 10390,
  "num_train_epochs": 10,
  "total_flos": 4697587831088826.0,
  "trial_name": null,
  "trial_params": null
}
